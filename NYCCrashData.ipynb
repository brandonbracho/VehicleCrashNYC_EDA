{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.style as style \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import scipy. stats as stats\n",
    "import math\n",
    "style.use('seaborn-poster') \n",
    "style.use('ggplot')\n",
    "import calendar\n",
    "import gmaps\n",
    "gmaps.configure(api_key=\"AIzaSyCobJCcwLjJzFw2Iz_1R66wWXqotu2rJTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV formatted data.\n",
    "df=pd.read_csv(\"Motor_Vehicle_Collisions_-_Crashes (1).csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first five rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the last fives rows of data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 1,016,734 rows and 29 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows that have all NaN values.\n",
    "df.dropna(how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will limit this EDA to just total amount of people killed or injured instead of specifics below.\n",
    "df.drop(columns=['NUMBER OF PEDESTRIANS INJURED',\n",
    "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
    "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
    "       'NUMBER OF MOTORIST KILLED'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a mixture of qualitative and quantitative data. We also appear to have a substantial\n",
    "# amount of NaN values.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming CRASH DATE and CRASH TIME columns into pandas Datetime objects.\n",
    "\n",
    "df[\"CRASH DATE\"]=pd.to_datetime(df[\"CRASH DATE\"])\n",
    "df[\"CRASH TIME\"]=pd.Series([row.time() for row in pd.to_datetime(df[\"CRASH TIME\"])])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of NaN (missing data) for each column. \n",
    "for column in df:\n",
    "    print(f\"{column}: {((df[column].isna().sum())/len(df))*100}%\")\n",
    "    \n",
    "# While columns such as CONTRIBUTING FACTOR VEHICLE 5 have very high percentages of missing\n",
    "# data, we will be keeping them as we will assume that if a row has a missing value in that \n",
    "# column, there were less than 5 vehicles in the instance of the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRASH DATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be doing a value count on the Crash Date Column to see what days had the most as\n",
    "# well as the least accidents. \n",
    "\n",
    "df[\"CRASH DATE\"].value_counts()\n",
    "\n",
    "# The most accidents during this 3 year period occured on November 11th 2018 during a snowstorm in which the city \n",
    "# ellicited a poor response. The least amount occured during the COVID-19 lockdown in April, 5th 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the counts on a boxplot\n",
    "sns.boxplot(x=df[\"CRASH DATE\"].value_counts())\n",
    "\n",
    "# From this we can see that the Median is approximately 592. 25% of the counts are equal or\n",
    "# less than approx. 477, 50% of the counts are equal or less than approximately 592 and 75% of the\n",
    "# counts are equal to or less than approx 669. The dataset presents several outliers in both\n",
    "# directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the actual numbers. \n",
    "\n",
    "df[\"CRASH DATE\"].value_counts().describe()\n",
    "\n",
    "# There are a total of 1827 different dates within the dataset, the mean and the median are \n",
    "# somewhat similar in value being 556 and 592 respectively with the mean being lower,\n",
    "# indicating that the counts may be slightly negatively skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the distribution. \n",
    "\n",
    "sns.distplot(df[\"CRASH DATE\"].value_counts())\n",
    "\n",
    "\n",
    "# From this we can see that the dataset follows somewhat of a less pronounced bimodal distribution. With peaks forming\n",
    "# in the 300 accidents and 600 accidents per day range respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at daily and total accident count trends over 2017-2020. We will create a column to extract the \n",
    "# year of a given accident. \n",
    "\n",
    "df[\"YEAR\"]=df[\"CRASH DATE\"].dt.year\n",
    "\n",
    "# We will then calculate the average number of accidents a day, grouped by year. \n",
    "\n",
    "average_by_year={}\n",
    "for m,l in df.groupby(\"YEAR\"):\n",
    "    average_by_year[m]=df[df[\"YEAR\"]==m][\"CRASH DATE\"].value_counts().mean()\n",
    "    \n",
    "average_by_year\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will plot the dictionary we obtained with the daily average vehicle accidents for each\n",
    "# year.\n",
    "\n",
    "keys=list(average_by_year.keys())\n",
    "vals=[float(average_by_year[k]) for k in keys]\n",
    "sns.barplot(keys,vals)\n",
    "plt.title(\"Average Daily Vehicle Accidents by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Daily Vehicle Accidents\")\n",
    "\n",
    "# As expected both the lowest daily average vehicle accidents occured in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a month column in order to analyze the trends of crashes amongst the months.\n",
    "\n",
    "df[\"MONTH\"]=df[\"CRASH DATE\"].dt.month.apply(lambda x: calendar.month_abbr[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will create an empty dictionary and append the average accidents across all years \n",
    "# for that month\n",
    "\n",
    "average_by_month={}\n",
    "for m, l in df.groupby(\"MONTH\",sort=False):\n",
    "    average_by_month[m]=df[df[\"MONTH\"]==m][\"CRASH DATE\"].value_counts().mean()\n",
    "\n",
    "average_by_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the average accidents reported per day in each month spanning across all years\n",
    "keys=list(average_by_month.keys())\n",
    "vals=[float(average_by_month[k]) for k in keys]\n",
    "sns.barplot(x=keys, y=vals)\n",
    "plt.title(\"Average Daily Vehicle Accidents by Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Daily Vehicle Accidents\")\n",
    "\n",
    "# While we saw the most amount of accidents in a day toward the end of the year in 2018,\n",
    "# it seems that on average June has the most accidents in a day. April has the least amount \n",
    "# of accidents per day on average, however, this can be due to the COVID-19 lockdown pulling\n",
    "# that number down. Accidents do tend to be lower in the beginning months of the year than\n",
    "# the middle or final months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a column for DAYOFTHEWEEK. From this we will compute if accidents are more likely to occur on certain\n",
    "# days of the week.\n",
    "\n",
    "\n",
    "df[\"DAYOFTHEWEEK\"]=df[\"CRASH DATE\"].dt.day_name()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and compute average value counts for each day of the week.\n",
    "\n",
    "average_by_weekday={}\n",
    "for m, l in df.groupby(\"DAYOFTHEWEEK\",sort=False):\n",
    "    average_by_weekday[m]=df[df[\"DAYOFTHEWEEK\"]==m][\"CRASH DATE\"].value_counts().mean()\n",
    "\n",
    "average_by_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot these average car accidents for each weekday.\n",
    "keys1=list(average_by_weekday.keys())\n",
    "vals1=[float(average_by_weekday[k]) for k in keys1]\n",
    "\n",
    "sns.barplot(keys1,vals1)\n",
    "plt.title(\"Average Vehicle Accidents by Weekday\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Number of Vehicle Accidents\")\n",
    "\n",
    "# From this graph we can see that accidents tend to be higher on Friday's. A couple of possible\n",
    "# forces could be at play here. Friday's do have the typical rush-hours seen with other \n",
    "# weekdays (Mon-Thurs), but are unique in that they are also a typical night-out weekday.\n",
    "# Does the fact that it is also a night-out weekday mean that it could possibly see\n",
    "# a lot of drinking and driving which already adds to the accidents stemming from rush hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's conduct an indepedent samples t-test to determine wether amount of vehicle crashes on \n",
    "# Fridays are statiscally different from amount of vehicle crashes occuring on Sunday.\n",
    "\n",
    "a=df[df[\"DAYOFTHEWEEK\"]=='Friday'][\"CRASH DATE\"].value_counts()\n",
    "b=df[df[\"DAYOFTHEWEEK\"]=='Sunday'][\"CRASH DATE\"].value_counts()\n",
    "\n",
    "stats.ttest_ind(a,b,equal_var=False)\n",
    "\n",
    "# We obtain a very low p-value suggesting that te vehicle crashes occuring on Friday's\n",
    "# are signficantly different from the amount occuring on Sunday. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRASH TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CRASH TIME refers to the time that the accident happened. We will be running a value count\n",
    "# to get the frequency of each unique crash time. \n",
    "\n",
    "df[\"CRASH TIME\"].value_counts()\n",
    "\n",
    "# It seems that the exact time in which most accidents occur is at 4pm, followed by midnight. Once time is broken into\n",
    "# ranges, the picture will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a new column to extrapolate the hour from CRASH TIME, in order to get a better\n",
    "# sense of the ranges in which accidents take place. \n",
    "\n",
    "df[\"HOUR\"]=df['CRASH TIME'].apply(lambda x: x.hour)\n",
    "df[\"HOUR\"].value_counts()\n",
    "\n",
    "# A very different picture is now painted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's obtain a little more information now that the times have been broken up into repsective\n",
    "# ranges. We are assuming that if a row contains a K-hour, the range of the actual time will\n",
    "# be anywhere from K:00 to K:59\n",
    "\n",
    "df[\"HOUR\"].describe()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the average number of accidents per hour on any given day\n",
    "average_crashes_hour={}\n",
    "for group, frame in df.groupby(\"HOUR\"):\n",
    "     average_crashes_hour[group]=int(df[df[\"HOUR\"]==group][\"HOUR\"].value_counts())/len(df[\"CRASH DATE\"].unique())\n",
    "average_crashes_hour        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot the averages above. \n",
    "\n",
    "keys2=list(average_crashes_hour.keys())\n",
    "vals2=[float(average_crashes_hour[k]) for k in keys2]\n",
    "sns.barplot(keys2,vals2)\n",
    "plt.title(\"Average Vehicle Accidents by Hour\")\n",
    "plt.xlabel(\"Hour (Military Time)\")\n",
    "plt.ylabel(\"Vehicle Accidents per Hour\")\n",
    "\n",
    "# Average accidents reach its peak around the 4 pm mark and then taper off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the BOROUGH column within the dataset to determine which borough\n",
    "# had the most and least accidents as well as to take a look at the distribution\n",
    "\n",
    "df[\"BOROUGH\"].value_counts()\n",
    "\n",
    "# Note that approxiametely 36% of the data in this column is made up of NaN values.\n",
    "# However, the counts for each borough appear to correlated to the borough's population\n",
    "# with Brookly having the most accidents and Staten Island having the least. This will be\n",
    "# confirmed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the total amount of accidents by Borough\n",
    "sns.countplot(df[\"BOROUGH\"])\n",
    "plt.ylabel(\"Total Vehicle Accidents\")\n",
    "plt.title(\"Total Vehicle Accidents by Borough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's import 2019 Census data in order to get an accurate population estimate. We will\n",
    "# concat data of 2019 accidents by borough to the population dataset.\n",
    "\n",
    "popdf=pd.read_csv(\"QuickFacts Mar-20-2021.csv\",thousands=',').iloc[[0],3:]\n",
    "popdf.dropna(axis=1,how='all',inplace=True)\n",
    "popdf.columns=[\"BRONX\",\"BROOKLYN\",\"MANHATTAN\",\"QUEENS\",\"STATEN ISLAND\"]\n",
    "borodf=pd.DataFrame(data=df[df[\"CRASH DATE\"].apply(lambda x: x.year)==2019][\"BOROUGH\"].value_counts()).T\n",
    "popboro=pd.concat([borodf,popdf])\n",
    "popboro.index=[\"CRASH TOTAL\",\"POP TOTAL\"]\n",
    "popboro=popboro.T\n",
    "popboro[\"POP TOTAL\"]=pd.to_numeric(popboro[\"POP TOTAL\"].str.replace(\",\",\"\"))\n",
    "popboro[\"CRASH TOTAL\"]=pd.to_numeric(popboro[\"CRASH TOTAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the correlation\n",
    "\n",
    "popboro.corr()\n",
    "\n",
    "# There is an almost a perfect correlation between population and car crashes within the \n",
    "# boroughs, suggesting that amount of accidents could possibly be a function of population of an area\n",
    "# in this case, a given borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally let's take a look at the crash to population ration of each borough.\n",
    "\n",
    "sns.barplot([\"BROOKLYN\",\"QUEENS\",\"MANHATTAN\",\"BRONX\",\"STATEN ISLAND\"],popboro[\"CRASH TOTAL\"]/popboro[\"POP TOTAL\"])\n",
    "plt.title(\"Vehicle Accidents per Capita by Borough\")\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Crashes per Capita\")\n",
    "\n",
    "# Queens appears to come out top slightly, followed by Brooklyn, Mahattan, the Bronx and Staten Island"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZIP CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let't take a look at different zip codes in NYC and which neighborhoods experience the most\n",
    "# and least car crashes. \n",
    "\n",
    "df[\"ZIP CODE\"].value_counts()\n",
    "\n",
    "# From this we can see that the most amount of accidents take place in zip code 11207 (East New York), and \n",
    "# several zip codes are contenders for the least amount of accidents. We will map zipcodes\n",
    "# to a list of neighborhoods to get their respective neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import a CSV containing NYC zip codes and their respective neighborhoods. We will map this data to our current \n",
    "# list of zipcodes.\n",
    "\n",
    "zipdf=pd.read_csv(\"hosp_death_last28days-by-modzcta.csv\")\n",
    "zipdf.dropna(inplace=True)\n",
    "zipdf[\"ZIP2\"]=zipdf[\"ZIP2\"].apply(lambda x: pd.to_numeric(x.split(\",\")))\n",
    "zipdf=zipdf.explode(\"ZIP2\")\n",
    "\n",
    "zipcodes={}\n",
    "\n",
    "for n in zipdf[\"ZIP2\"]:\n",
    "    zipcodes[n]=zipdf[zipdf[\"ZIP2\"]==n][\"NEIGHBORHOOD\"].values[0]\n",
    "    \n",
    "zipcodes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will manually \"hard-code\" any zipcodes that have missing neighborhoods.\n",
    " \n",
    "zipcodes[11001]=\"Floral Park\"\n",
    "zipcodes[10172]= \"East Midtown\"\n",
    "zipcodes[11695]=\"Far Rockaway\"\n",
    "zipcodes[11040]=\"New Hyde Park\"\n",
    "zipcodes[10169]=\"East Midtown\"\n",
    "zipcodes[11430]=\"Airport/South Jamaica/Springfield Gardens/St. Albans\"\n",
    "zipcodes[10000]=\"Midtown South\"\n",
    "zipcodes[10281]=\"Battery Park City\"\n",
    "zipcodes[10168]=\"Murray Hill\"\n",
    "zipcodes[10119]=\"Midtown South\"\n",
    "zipcodes[10123]=\"Garment District\"\n",
    "zipcodes[10165]=\"Murray Hill\"\n",
    "zipcodes[10154]=\"East Midtown\"\n",
    "zipcodes[10120]=\"Garment District\"\n",
    "zipcodes[10153]=\"East Midtown\"\n",
    "zipcodes[10170]=\"East Midtown\"\n",
    "zipcodes[10171]=\"East Midtown\"\n",
    "zipcodes[10121]=\"Koreatown\"\n",
    "zipcodes[10110]=\"Midtown\"\n",
    "zipcodes[10105]=\"Midtown\"\n",
    "zipcodes[10271]=\"Financial District\"\n",
    "zipcodes[10112]=\"Diamond District\"\n",
    "zipcodes[10111]=\"Diamond District\"\n",
    "zipcodes[10174]=\"East Midtown\"\n",
    "zipcodes[10278]=\"Tribeca\"\n",
    "zipcodes[10155]=\"East Midtown\"\n",
    "zipcodes[10151]=\"East Midtown\"\n",
    "zipcodes[10167]=\"East Midtown\"\n",
    "zipcodes[10041]=\"Financial District\"\n",
    "zipcodes[10173]=\"Midtown\"\n",
    "zipcodes[10107]=\"Hell's Kitchen\"\n",
    "zipcodes[10106]=\"Hell's Kitchen\"\n",
    "zipcodes[11242]=\"Brooklyn Heights\"\n",
    "zipcodes[10178]=\"Midtown\"\n",
    "zipcodes[11241]=\"Brooklyn Heights\"\n",
    "zipcodes[10279]=\"Financial District\"\n",
    "zipcodes[10045]=\"Financial District\"\n",
    "zipcodes[10152]=\"East Midtown\"\n",
    "zipcodes[10177]=\"East Midtown\"\n",
    "zipcodes[11359]=\"Bayside (North)\"\n",
    "zipcodes[10103]=\"Diamond District\"\n",
    "zipcodes[10176]=\"Midtown\"\n",
    "zipcodes[10122]=\"Midtown South\"\n",
    "zipcodes[10158]=\"Murray Hill\"\n",
    "zipcodes[10179]=\"East Midtown\"\n",
    "zipcodes[10115]=\"Morningside Heights\"\n",
    "zipcodes[10055]=\"East Midtown\"\n",
    "zipcodes[11251]=\"Brooklyn Navy Yard\"\n",
    "\n",
    "# We use apply to map the neighborhoods from the dictionary above, to their respective zipcodes in the original\n",
    "# dataframe. They will be represented in a separate column.\n",
    "\n",
    "df[\"NEIGHBORHOOD\"]=df[\"ZIP CODE\"].apply(lambda x: zipcodes[x] if x in zipcodes else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NEIGHBORHOOD\"].value_counts()\n",
    "\n",
    "# From this we can see that the most accidents come from Hell's Kitchen in\n",
    "# Manhattan. Note that some neighborhoods cotain mutiple zip codes while others only contain\n",
    "# one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATITUDE AND LONGITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_layout={\n",
    "    'width':'850px',\n",
    "    'height':'750px',\n",
    "    'border':'3px solid black',\n",
    "    'padding':'3px'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a function that converts Longitudes to a format in which they are between -180 and 180. This will allow us \n",
    "# to plot them onto a heatmap. \n",
    "\n",
    "coordinates=df.loc[:,[\"LATITUDE\",\"LONGITUDE\"]]\n",
    "coordinates.dropna(inplace=True)\n",
    "def long_func(x):\n",
    "    if x> 180:\n",
    "        x-=360\n",
    "    elif x< -180:\n",
    "        x+=360\n",
    "    return x\n",
    "\n",
    "# Apply the function above to all rows in LONGITUDE column\n",
    "coordinates[\"LONGITUDE\"]=coordinates[\"LONGITUDE\"].apply(lambda x: long_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configurations for the heatmap\n",
    "\n",
    "fig=gmaps.figure(layout=fig_layout)\n",
    "heatmap_layer=gmaps.heatmap_layer(coordinates)\n",
    "heatmap_layer.max_intensity =100\n",
    "heatmap_layer.point_radius = 5\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll take a look at the most common ON STREET NAME which refer to the street in which an accident took place.\n",
    "# Please note that approxiamntely %25 of data from this coulmn is missing. \n",
    "\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].apply(lambda x: str(x).upper() if pd.isnull(x)==False else x)\n",
    "df[\"ON STREET NAME\"].value_counts()[:60]\n",
    "\n",
    "# From this we can see that the majority of the accidents take place in highways. This makes complete sense\n",
    "# as highways see a much greater volume of traffic than individual streets. After highways, we see the most accidents\n",
    "# on boulevards and avenues which also receive a higher amount of traffic than streets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the total number of injuries associated with each respective street name.\n",
    "injuriesstreet=[]\n",
    "for group, frame in df.groupby(\"ON STREET NAME\"):\n",
    "    injuriesstreet.append((group,frame[\"NUMBER OF PERSONS INJURED\"].sum()))\n",
    "\n",
    "sorted(injuriesstreet,key=lambda x: x[1],reverse=True)\n",
    "    \n",
    "\n",
    "# The top 5 ON STREET NAMES associated with the most injuries are all highways with the exception of Atlantic Ave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the total number of deaths assocaited with each respective street name. \n",
    "\n",
    "deathsstreet=[]\n",
    "for group, frame in df.groupby(\"ON STREET NAME\"):\n",
    "    deathsstreet.append((group,frame[\"NUMBER OF PERSONS KILLED\"].sum()))\n",
    "\n",
    "sorted(deathsstreet,key=lambda x: x[1],reverse=True)\n",
    "\n",
    "# This paints a completely different picture. The top 5 dealiest ON STREET NAMES are a mixture of highways, boulevards,\n",
    "# and avenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will get rid of any abbreviations of words and replace them with the actual word.\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" PKWY \",\"PARKWAY\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" EXPWY \",\"EXPRESSWAY\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" EXPY \",\"EXPRESSWAY\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" BLVD \",\"BOULEVARD\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" AVE \",\"AVENUE\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" ST \",\"STREET\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" RD \",\"ROAD\")\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\" PL \",\"PLACE\")\n",
    "# For simplicity's sake we will be renaming Broadway to Broaday Avenue \n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.replace(\"BROADWAY\",\"BROADWAY AVENUE\")\n",
    "# Remove any trailing whitespace the street name may have.\n",
    "df[\"ON STREET NAME\"]=df[\"ON STREET NAME\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's rise the following quesiton, on what type of streets/roads (Boulevards, Streets, Expressways, Parkways, etc.)\n",
    "# do injuries and deaths occur the most?\n",
    "\n",
    "# We extract any key words that may indicate the type of street we are dealing with. \n",
    "df[\"ROADTYPE\"]=df[\"ON STREET NAME\"].str.extract(r'(?:.*)(HIGHWAY|STREET|AVENUE|EXPRESSWAY|ROAD|PARKWAY|BOULEVARD|TURNPIKE|PLACE|DRIVE|LANE|RAMP|BRIDGE|TUNNEL)(?:.*)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ROADTYPE\"].value_counts()\n",
    "\n",
    "# The amount of accidents on avenues and roads are larger than the amount of accidents on expressways or parkways. \n",
    "# This is likely due to the fact that there are just most avenues and streets than there are expressways and parkways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the dealiest/most dangerous type of road/street to be on? We will calculate both injuries associated with\n",
    "# street/road type as well as deaths. To provide a clearer picture, we will calculate this on a per accident basis.\n",
    "\n",
    "roadtype={}\n",
    "for group, frame in df.groupby(\"ROADTYPE\"):\n",
    "    roadtype[group]=(frame[\"NUMBER OF PERSONS INJURED\"].sum())/len(frame)\n",
    "    \n",
    "roadtype\n",
    "# Highway proves to be the type of street/road with the most injuries per accident followed by parkways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keysroad=list(roadtype.keys())\n",
    "valsroad=[float(roadtype[k]) for k in keysroad]\n",
    "sns.barplot(keysroad,valsroad)\n",
    "plt.title(\"Number of Persons Injured per Accident by Road/Street Type\")\n",
    "plt.xlabel(\"Type of Road/Street\")\n",
    "plt.ylabel(\"Number of People Injured per Accident\")\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now explore the same quesiton but in relation to deaths. \n",
    "\n",
    "roadtypedeath={}\n",
    "for group, frame in df.groupby(\"ROADTYPE\"):\n",
    "    roadtypedeath[group]=(frame[\"NUMBER OF PERSONS KILLED\"].sum())/len(frame)\n",
    "    \n",
    "roadtypedeath\n",
    "# Turnpikes appear to be disproportionately deadlier than any other type of road/street. Followed by boulevards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keysroadd=list(roadtypedeath.keys())\n",
    "valsroadd=[float(roadtypedeath[k]) for k in keysroadd]\n",
    "sns.barplot(keysroadd,valsroadd)\n",
    "plt.title(\"Number of Persons Killed per Accident by Road/Street Type\")\n",
    "plt.xlabel(\"Type of Road/Street\")\n",
    "plt.ylabel(\"Number of People Killed per Accident\")\n",
    "plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Persons Injured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the number of people injured. We will explore the time in which most people are injured, \n",
    "# the location, etc. \n",
    "\n",
    "# Let's take a look at the values counts of amount of people injured.\n",
    "df[\"NUMBER OF PERSONS INJURED\"].value_counts()\n",
    "\n",
    "# As expected the higher the number of people injured, the rarer the instance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the distribution is plotted on a box plot, it records everything other than 0 people injured as an outlier. \n",
    "# Therefore, it should be noted that injuries in accidents are somewhat rare. \n",
    "\n",
    "sns.boxplot(df[\"NUMBER OF PERSONS INJURED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dates with the most persons injured. \n",
    "\n",
    "injuriesdate={}\n",
    "for date, frame in df.groupby(\"CRASH DATE\"):\n",
    "    injuriesdate[date]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "pd.DataFrame.from_dict(injuriesdate,orient='index',columns=[\"NUMBER OF PERSONS INJURED\"]).sort_values(by=[\"NUMBER OF PERSONS INJURED\"],ascending=False)\n",
    "\n",
    "# Here we're taking a look at the days with most individuals injured. 5/18/2017 is the day with most people injured.\n",
    "# This was the day of the 2017 times square crash that injured 20 people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the year with most injuries. \n",
    "\n",
    "injuriesyear={}\n",
    "for year, frame in df.groupby(\"YEAR\"):\n",
    "    injuriesyear[year]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "injuriesyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys2=list(injuriesyear.keys())\n",
    "vals2=[float(injuriesyear[k]) for k in keys2]\n",
    "sns.barplot(keys2,vals2)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Injuries\")\n",
    "plt.title(\"Total Number of Injuries per Year\")\n",
    "\n",
    "# It is clearly seen that the number of injuries were pretty similar in 2017-2019 but dropped signficantly in 2020.\n",
    "# This can most likely be attributed to the pandemic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total injuries are expectingly correlated with total number of accidents, therefore we will calculate injuries per\n",
    "# accident along with total injuries for each section going forward. \n",
    "\n",
    "# Lets calculate the injuries per accident for each year. \n",
    "\n",
    "injuriesaccidentyear={}\n",
    "for year, frame in df.groupby(\"YEAR\"):\n",
    "    injuriesaccidentyear[year]=frame[\"NUMBER OF PERSONS INJURED\"].sum()/len(frame)\n",
    "injuriesaccidentyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys02=list(injuriesaccidentyear.keys())\n",
    "vals02=[float(injuriesaccidentyear[k]) for k in keys02]\n",
    "sns.barplot(keys02,vals02)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Injuries per Accident\")\n",
    "\n",
    "# This graph paints a completely different picture than the one above, where there were significantly more injuries \n",
    "# per accident in 2020 compared to the previous years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the total number of injuries in each month. \n",
    "\n",
    "injuriesmonth={}\n",
    "for month,frame in df.groupby(\"MONTH\"):\n",
    "    injuriesmonth[month]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "injuriesmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys3=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "vals3=[float(injuriesmonth[k]) for k in keys3]\n",
    "sns.barplot(keys3,vals3)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Injuries\")\n",
    "plt.title(\"Total Number of Injuries per Month\")\n",
    "\n",
    "# Injuries appear to peak during the summer months, and fall during winter and spring months.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the number of injuries per accident for each month. \n",
    "injuriesaccidentmonth={}\n",
    "for month, frame in df.groupby(\"MONTH\"):\n",
    "    injuriesaccidentmonth[month]=frame[\"NUMBER OF PERSONS INJURED\"].sum()/len(frame)\n",
    "injuriesaccidentmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys03=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "vals03=[float(injuriesaccidentmonth[k]) for k in keys03]\n",
    "sns.barplot(keys03,vals03)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Injuries per Accident\")\n",
    "plt.title(\"Number of Injuries per Accident by Month\")\n",
    "\n",
    "# We still see a similar trend in this graph with injuries per accident ramping up in the summer months and lowest in\n",
    "# the early spring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the injuries sustained on each day of the week. \n",
    "injuriesbyday={}\n",
    "\n",
    "for day, frame in df.groupby(\"DAYOFTHEWEEK\"):\n",
    "    injuriesbyday[day]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "injuriesbyday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys4=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "vals4=[float(injuriesbyday[k]) for k in keys4]\n",
    "sns.barplot(keys4, vals4)\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel('Total Number of Injuries')\n",
    "plt.title(\"Total Number of Injuries by Day of the Week\")\n",
    "\n",
    "# As with total number of accidents on each day of the week, Friday has the most injuries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the injuries per accident during each day of the week. \n",
    "dayinjuriesaccident={}\n",
    "for day, frame in df.groupby(\"DAYOFTHEWEEK\"):\n",
    "    dayinjuriesaccident[day]=frame[\"NUMBER OF PERSONS INJURED\"].sum()/len(frame)\n",
    "dayinjuriesaccident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys04=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "vals04=[float(dayinjuriesaccident[k]) for k in keys04]\n",
    "sns.barplot(keys04, vals04)\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel('Total Number of Injuries per Accident')\n",
    "plt.title(\"Number of Injuries per Accident by Day of the Week\")\n",
    "\n",
    "# This graph paints a different picture than the one above. There seems to be signficantly more injuries per accident\n",
    "# during the weekend. Could this difference be attributed to the fact that more people consume alcohol on weekends\n",
    "# leading to a higher instance of drunk driving and therefore injuries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the number of injuries during each hour of the day. \n",
    "\n",
    "injurieshour={}\n",
    "for hour, frame in df.groupby(\"HOUR\"):\n",
    "    injurieshour[hour]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "injurieshour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys5=list(injurieshour.keys())\n",
    "vals5=[float(injurieshour[k]) for k in keys5]\n",
    "sns.barplot(keys5,vals5)\n",
    "plt.xlabel(\"Hour (Military Time)\")\n",
    "plt.ylabel('Total Number of Injuries')\n",
    "plt.title(\"Total Number of Injuries per Hour\")\n",
    "\n",
    "# This graph follows the same trend as the average car crashes per hour graph does, suggesting that the number of\n",
    "# injuries in an hour is merely a funciton of the amount of total crashes per hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the number of injuries per accident for each hour. \n",
    "\n",
    "injuriesaccidenthour={}\n",
    "for hour, frame in df.groupby(\"HOUR\"):\n",
    "    injuriesaccidenthour[hour]=frame[\"NUMBER OF PERSONS INJURED\"].sum()/len(frame)\n",
    "injuriesaccidenthour\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys05=list(injuriesaccidenthour.keys())\n",
    "vals05=[float(injuriesaccidenthour[k]) for k in keys05]\n",
    "sns.barplot(keys05,vals05)\n",
    "plt.xlabel(\"Hour (Military Time)\")\n",
    "plt.ylabel('Number of Injuries per Accident')\n",
    "plt.title(\"Number of Injuries per Accident by Hour\")\n",
    "\n",
    "# This paints a completely different picture with the highest rates of injuries per accident happening in the late\n",
    "# night and early morning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the neighborhoods/zip codes with the most amount of injuries. \n",
    "\n",
    "zipinjury=[]\n",
    "for zipcode, frame in df.groupby(\"ZIP CODE\"):\n",
    "       zipinjury.append((zipcode, frame[\"NUMBER OF PERSONS INJURED\"].sum()))\n",
    "        \n",
    "zipinjury=sorted(zipinjury,key=lambda x: x[1], reverse=True)\n",
    "\n",
    "neighborhoods=[]\n",
    "for n in zipinjury:\n",
    "    neighborhoods.append(df[df[\"ZIP CODE\"]==n[0]][\"NEIGHBORHOOD\"].values[0])\n",
    "list(zip(zipinjury,neighborhoods))\n",
    "\n",
    "# From this list, it seems like the majority of the injuries take place in Brooklyn zipcodes/neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at injuries in each of the boroughs. \n",
    "\n",
    "boroughinjuries={}\n",
    "for borough, frame in df.groupby(\"BOROUGH\"):\n",
    "    boroughinjuries[borough]=frame[\"NUMBER OF PERSONS INJURED\"].sum()\n",
    "boroughinjuries\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys6=list(boroughinjuries.keys())\n",
    "vals6=[float(boroughinjuries[k]) for k in keys6]\n",
    "\n",
    "sns.barplot(keys6,vals6)\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Total Injuries\")\n",
    "plt.title(\"Total Numberof Injuries by Borough\")\n",
    "\n",
    "# There appears to be 25% more injuries in Brooklyn than in Queens, and the Bronx, Mahattan and Staten Island have\n",
    "# significantly less total injuries. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boroughinjuries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-37af509d4ef2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minjuriesbycrash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboroughinjuries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0minjuriesbycrash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboroughinjuries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BOROUGH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boroughinjuries' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's adjust these numbers to represent injuries per car crash. \n",
    "\n",
    "injuriesbycrash={}\n",
    "for n in boroughinjuries.keys():\n",
    "    injuriesbycrash[n]=boroughinjuries[n]/len(df[df[\"BOROUGH\"]==n])\n",
    "    \n",
    "injuriesbycrash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys7=list(injuriesbycrash.keys())\n",
    "vals7=[float(injuriesbycrash[k]) for k in keys7]\n",
    "\n",
    "sns.barplot(keys7,vals7)\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.ylabel(\"Injuries per Accident\")\n",
    "plt.title(\"Number of Injuries per Accident by Borough\")\n",
    "\n",
    "# The numbers are now closer together with the exception of Manhattan, where injuries on a per accident basis \n",
    "# are significantly lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a heatmap with respect to the car crash injuries. \n",
    "\n",
    "coordinates1=df.loc[:,[\"LATITUDE\",\"LONGITUDE\",\"NUMBER OF PERSONS INJURED\"]]\n",
    "coordinates1.dropna(inplace=True)\n",
    "\n",
    "# Apply the function above to all rows in LONGITUDE column\n",
    "coordinates1[\"LONGITUDE\"]=coordinates1[\"LONGITUDE\"].apply(lambda x: long_func(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMBER OF PERSONS KILLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the distribution of individuals killed during an accident in NYC.\n",
    "df[\"NUMBER OF PERSONS KILLED\"].value_counts()\n",
    "\n",
    "# Deaths during accidents are extremely rare as seen in chart below. The majority of accidents go without any deaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"NUMBER OF PERSONS KILLED\"])\n",
    "\n",
    "# The box plot below displays all values above 0 as extreme outliers, indicating deaths in a car accident are rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the dates with the most people that passed away in accidents. \n",
    "\n",
    "deathsdate={}\n",
    "for date, frame in df.groupby(\"CRASH DATE\"):\n",
    "    deathsdate[date]=frame[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "\n",
    "pd.DataFrame.from_dict(deathsdate,orient='index', columns=[\"NUMBER OF PERSONS KILLED\"]).sort_values(by=[\"NUMBER OF PERSONS KILLED\"],ascending=False).head(50)\n",
    "# Below, the 50th deadliest days are shown with 10-31-2017 being the deadliest day by far with 10 deaths,    \n",
    "# which was the day of the 2017 New York City truck attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the years with most deaths. \n",
    "\n",
    "deathsyear={}\n",
    "for year, frame in df.groupby(\"YEAR\"):\n",
    "    deathsyear[year]=frame[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "deathsyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys7=list(deathsyear.keys())\n",
    "vals7=[float(deathsyear[k]) for k in keys7]\n",
    "sns.barplot(keys7,vals7)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Deaths per Year\")\n",
    "plt.title(\"Total Number of Deaths from Accidents by Year\")\n",
    "\n",
    "# It seems that 2020 had the most deaths out of all the years despite having the least total accidents. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the number of deaths per accident for each year.\n",
    "\n",
    "deathsperaccidentyr={}\n",
    "for year, frame in df.groupby(\"YEAR\"):\n",
    "    deathsperaccidentyr[year]=frame[\"NUMBER OF PERSONS KILLED\"].sum()/len(frame)\n",
    "deathsperaccidentyr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys07=list(deathsperaccidentyr.keys())\n",
    "vals07=[float(deathsperaccidentyr[k]) for k in keys07]\n",
    "sns.barplot(keys07,vals07)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Deaths per Accient\")\n",
    "plt.title(\"Deaths per Accident by Year\")\n",
    "\n",
    "# 2020 has more than double of the amount of deaths per accident than 2017, 2018 and 2019. Roads with less traffic\n",
    "# due to the pandemic led to excessive speeding and therefore more deaths during 2020. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the total deaths occuring during each month. \n",
    "deathsmonth={}\n",
    "\n",
    "for month, frame in df.groupby(\"MONTH\"):\n",
    "    deathsmonth[month]=frame[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "deathsmonth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys8=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "vals8=[float(deathsmonth[k]) for k in keys8]\n",
    "sns.barplot(keys8,vals8)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Total Deaths \")\n",
    "plt.title(\"Deaths per Month\")\n",
    "\n",
    "# Here we can see total deaths per month follow a slightly different trend than the number of tota accidents or injuries \n",
    "# per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the deaths per accident ratio. \n",
    "deathsaccidentmonth={}\n",
    "\n",
    "for month, frame in df.groupby(\"MONTH\"):\n",
    "    deathsaccidentmonth[month]=frame[\"NUMBER OF PERSONS KILLED\"].sum()/len(frame)\n",
    "deathsaccidentmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys08=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "vals08=[float(deathsaccidentmonth[k]) for k in keys08]\n",
    "sns.barplot(keys08,vals08)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Deaths per Accient\")\n",
    "plt.title(\"Deaths per Accident by Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the total deaths per day of the week\n",
    "\n",
    "deathsday={}\n",
    "for day, frame in df.groupby(\"DAYOFTHEWEEK\"):\n",
    "    deathsday[day]=frame[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "    \n",
    "deathsday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys9=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "vals9=[float(deathsday[k]) for k in keys9]\n",
    "sns.barplot(keys9, vals9)\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel('Total Number of Deaths')\n",
    "plt.title(\"Total Number of Deaths from Accidents per Day\")\n",
    "\n",
    "# Saturdays are a good amount higher on total deaths than the other days of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at deaths per accident during days of the week.\n",
    "\n",
    "deathsaccday={}\n",
    "for day, frame in df.groupby(\"DAYOFTHEWEEK\"):\n",
    "    deathsaccday[day]=frame[\"NUMBER OF PERSONS KILLED\"].sum()/len(frame)\n",
    "deathsaccday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys09=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "vals09=[float(deathsaccday[k]) for k in keys09]\n",
    "sns.barplot(keys09, vals09)\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel('Deaths per accident')\n",
    "plt.title(\"Deaths per Accident by Day of the Week\")\n",
    "\n",
    "# The trend in this graph follows somewhat the same trend as the previous, but on this one both weekend days appear\n",
    "# to be way more deadly on a per accident basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out the total number of deaths per hour \n",
    "\n",
    "deathshour={}\n",
    "for hour, frame in df.groupby(\"HOUR\"):\n",
    "    deathshour[hour]=frame[\"NUMBER OF PERSONS KILLED\"].sum()\n",
    "    \n",
    "deathshour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys10=list(deathshour.keys())\n",
    "vals10=[float(deathshour[k]) for k in keys10]\n",
    "sns.barplot(keys10,vals10)\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Total Number of Deaths\")\n",
    "plt.title(\"Total Deaths per Hour\")\n",
    "\n",
    "# This hourly graph shows a completely different trend than the one showing the total number of injuries or accidents \n",
    "# per hour. Deaths appear to be higher at night than during both rush hours despite having signficantly less accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's adjust the deaths to a per accident basis. \n",
    "\n",
    "deathsacchour={}\n",
    "for hour, frame in df.groupby(\"HOUR\"):\n",
    "    deathsacchour[hour]=frame[\"NUMBER OF PERSONS KILLED\"].sum()/len(frame)\n",
    "deathsacchour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys100=list(deathsacchour.keys())\n",
    "vals100=[float(deathsacchour[k]) for k in keys100]\n",
    "sns.barplot(keys100,vals100)\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Deaths per Accident\")\n",
    "plt.title(\"Deaths per Accident by Hour\")\n",
    "\n",
    "# When reporting deaths on a per accident basis, deaths are extremely high during the early morning hours particularly\n",
    "# 3am and 4am. I am predicting this is due to a higher incidence of drunk driving at this time, as NYC bars and clubs\n",
    "# close around this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the deadliest zip codes/neighborhoods when it comes to car accidents. \n",
    "zipdeaths=[]\n",
    "for zipcode, frame in df.groupby(\"ZIP CODE\"):\n",
    "       zipdeaths.append((zipcode, frame[\"NUMBER OF PERSONS KILLED\"].sum()))\n",
    "        \n",
    "zipdeaths=sorted(zipdeaths,key=lambda x: x[1], reverse=True)\n",
    "\n",
    "neighborhoods=[]\n",
    "for n in zipdeaths:\n",
    "    neighborhoods.append(df[df[\"ZIP CODE\"]==n[0]][\"NEIGHBORHOOD\"].values[0])\n",
    "list(zip(zipdeaths,neighborhoods))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRIBUTING FACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the contributing factors within different accidents. Firstly, let's take a look at all the \n",
    "# different values this column can take. \n",
    "\n",
    "df.replace('80',np.nan,inplace=True)\n",
    "df.replace('1', np.nan, inplace=True)\n",
    "\n",
    "print(pd.unique(df[[\"CONTRIBUTING FACTOR VEHICLE 1\",\"CONTRIBUTING FACTOR VEHICLE 2\",\"CONTRIBUTING FACTOR VEHICLE 3\",\"CONTRIBUTING FACTOR VEHICLE 4\",\"CONTRIBUTING FACTOR VEHICLE 5\"]].values.ravel('K')))\n",
    "df[[\"CONTRIBUTING FACTOR VEHICLE 1\",\"CONTRIBUTING FACTOR VEHICLE 2\",\"CONTRIBUTING FACTOR VEHICLE 3\",\"CONTRIBUTING FACTOR VEHICLE 4\",\"CONTRIBUTING FACTOR VEHICLE 5\"]].describe()\n",
    "\n",
    "# We have a total of 59 unique values in this column with \"Driver Inattention/Distraction\" being the lead contributing\n",
    "# factor in the first vehicle, and the rest being unspecified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the value counts for each column\n",
    "\n",
    "contridf=df[[\"CONTRIBUTING FACTOR VEHICLE 1\",\"CONTRIBUTING FACTOR VEHICLE 2\",\"CONTRIBUTING FACTOR VEHICLE 3\",\"CONTRIBUTING FACTOR VEHICLE 4\",\"CONTRIBUTING FACTOR VEHICLE 5\"]].apply(pd.Series.value_counts).sort_values(by=\"CONTRIBUTING FACTOR VEHICLE 1\",ascending=False)\n",
    "contridf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sum up all the rows in the DataFrame above to see which were the highest contributing factors to accidents\n",
    "contridf.sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "contridf.drop(\"Unspecified\",inplace=True)\n",
    "\n",
    "contridf\n",
    "\n",
    "# Unspecified is the most common contributing factor but sadly that does not give us any information,therfore, we will\n",
    "# drop it. The next mostcommon contributing factor is Driver Inattention/Distraction, followed by Following Too Closely and then \n",
    "# Failure to Yield Right-of-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,60))\n",
    "contridf.sum(axis=1).sort_values(ascending=False).plot(kind=\"barh\",logx=True)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title(\"Contributing Factors Count\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n",
    "plt.xlabel(\"Number of Occurences\",fontdict={'fontsize':50,'fontweight':\"bold\"},)\n",
    "plt.ylabel(\"Contributing Factors\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the total number of injuries associated with each Contributing Factor. Please note that the same \n",
    "# injur(y)(ies) can be counted multiple times as there are accidents in which there are mutiple and different Contribu-\n",
    "# ting factors. Therefore, the total number of persons injured in the DataFrame below reflects the total number of \n",
    "# injuries associated with the respective Contributing Factor.\n",
    "coninjframes=df.groupby(\"CONTRIBUTING FACTOR VEHICLE 1\").agg({\"NUMBER OF PERSONS INJURED\":np.sum}).sort_values(by=\"NUMBER OF PERSONS INJURED\", ascending=False)\n",
    "for n in [2,3,4,5]:\n",
    "    coninjframes=coninjframes.add(df.groupby(f\"CONTRIBUTING FACTOR VEHICLE {n}\").agg({\"NUMBER OF PERSONS INJURED\":np.sum}).sort_values(by=\"NUMBER OF PERSONS INJURED\", ascending=False),fill_value=0)\n",
    "\n",
    "coninjframes.drop(\"Unspecified\",inplace=True)\n",
    "\n",
    "# Once again unspecified contains the largest sum but does not contain any meaningful information, we will drop it.\n",
    "# The Contributing Vehicle Factor that was associated with the most injuries was Driver Inattention/Distraction followed\n",
    "# by Following Too Closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coninjframes.sort_values(by=\"NUMBER OF PERSONS INJURED\",ascending=False).plot(kind=\"barh\",logx=False,figsize=(40,60))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title(\"Total Number of Injuries Associated with Contributing Factor\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n",
    "plt.xlabel(\"Total Number of Injuries\",fontdict={'fontsize':50,'fontweight':\"bold\"},)\n",
    "plt.ylabel(\"Contributing Factors\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the total number of persons killed associated with each Contributing Factor. Please note that\n",
    "# an accident can have several contributing factors therefore the numbers in the DataFrame below represent the amount \n",
    "# of fatalities associated with each respective contributing factor. \n",
    "\n",
    "conkillframes=df.groupby(\"CONTRIBUTING FACTOR VEHICLE 1\").agg({\"NUMBER OF PERSONS KILLED\":np.sum}).sort_values(by=\"NUMBER OF PERSONS KILLED\", ascending=False)\n",
    "for n in [2,3,4,5]:\n",
    "    conkillframes=conkillframes.add(df.groupby(f\"CONTRIBUTING FACTOR VEHICLE {n}\").agg({\"NUMBER OF PERSONS KILLED\":np.sum}).sort_values(by=\"NUMBER OF PERSONS KILLED\", ascending=False),fill_value=0)\n",
    "\n",
    "conkillframes.drop(\"Unspecified\",inplace=True)\n",
    "\n",
    "conkillframes.sort_values(by=\"NUMBER OF PERSONS KILLED\",ascending=False)\n",
    "\n",
    "# We drop 'unspecified' as we did in the other DataFrames. The deadliest contributing factor appears to be Unsafe Speed,\n",
    "# followed by Driver Inattention/Distraction and Failure to Yield Right-of-Way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the DataFrame above.\n",
    "\n",
    "conkillframes.sort_values(by=\"NUMBER OF PERSONS KILLED\",ascending=False).plot(kind=\"barh\",figsize=(40,60))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.title(\"Total Number of Fatalities Associated with Contributing Factor\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n",
    "plt.xlabel(\"Total Number of Fatalities\",fontdict={'fontsize':50,'fontweight':\"bold\"},)\n",
    "plt.ylabel(\"Contributing Factors\",fontdict={'fontsize':50,'fontweight':\"bold\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at amount of times 'Alcohol Involvment' was a contributing factor to an accident during each\n",
    "# day of the week.\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"DAYOFTHEWEEK\"].value_counts()\n",
    "\n",
    "# We can see that Sunday's are the most common day for accidents involving alcohol. The highest concetration of \n",
    "# accidents is most likely in early hours of Sunday morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the most common hours for 'alcohol involvement' on a Sunday. \n",
    "\n",
    "df[((df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\"))& (df[\"DAYOFTHEWEEK\"]==\"Sunday\")][\"HOUR\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the number of accidents involving alcohol on a Sunday by hour. \n",
    "\n",
    "df[((df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\"))& (df[\"DAYOFTHEWEEK\"]==\"Sunday\")][\"HOUR\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.xlabel(\"Hour (Military Time)\")\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol on a Sunday by Hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting all days to follow a similar trend as Sunday, let's look at the number of accidents involving alcohol by\n",
    "# hour. \n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"HOUR\"].value_counts()\n",
    "\n",
    "# As hypothesized, most accidents involving alcohol occur during the late nights and early mornings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the data above.\n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"HOUR\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol by Hour\")\n",
    "plt.ylabel(\"Number of accidents\")\n",
    "plt.xlabel(\"Hour (Military Time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In an attempt to obtain insight into drinking habits, lets take a look at the number of accidents involving alcohol\n",
    "# by months\n",
    "\n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"MONTH\"].value_counts()\n",
    "\n",
    "# Despite May not having the highest total number of total accidents, it does have the highest\n",
    "# instances of accidents involving alcohol. This however does not seem to be signifcant as the values do not differ\n",
    "# greatly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the data above\n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"MONTH\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol by Month\")\n",
    "plt.ylabel(\"Number of accidents\")\n",
    "plt.xlabel(\"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the ratio of accidents involving alcohol to the number of total accidents by month in order\n",
    "# to get a clearer picture. \n",
    "\n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"MONTH\"].value_counts()/df[\"MONTH\"].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# This paints a different picture. April has the most accidents involving alcohol on a per accident basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the data above\n",
    "(df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"MONTH\"].value_counts()/df[\"MONTH\"].value_counts()).plot(kind=\"bar\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol by Month\")\n",
    "plt.ylabel(\"Number of accidents\")\n",
    "plt.xlabel(\"Month\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at accidents involving alcohol by year. \n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"YEAR\"].value_counts()\n",
    "\n",
    "# The numbers have been declining over the past couple of years with 2020 seeing the lowest number. With bars, clubs and\n",
    "# any other venues that put people at the risk of drinking and driving shut down, it makes logical sense why 2020\n",
    "# would have the lowest amount of accidents involving drinking and driving. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"YEAR\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol by Year\")\n",
    "plt.ylabel(\"Number of accidents\")\n",
    "plt.xlabel(\"Year\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the number of accidents involving alcohol per accident by year, \n",
    "\n",
    "df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"YEAR\"].value_counts()/df[\"YEAR\"].value_counts()\n",
    "\n",
    "# The number of accidents involving alcohol per accident saw a decline from 2016-2019 and actually shot up in 2020.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df[\"CONTRIBUTING FACTOR VEHICLE 1\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 2\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 3\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 4\"]==\"Alcohol Involvement\")|(df[\"CONTRIBUTING FACTOR VEHICLE 5\"]==\"Alcohol Involvement\")][\"YEAR\"].value_counts()/df[\"YEAR\"].value_counts()).plot(kind=\"bar\")\n",
    "plt.title(\"Number of Accidents Involving Alcohol per Accident by Year\")\n",
    "plt.ylabel(\"Number of accidents\")\n",
    "plt.xlabel(\"Year\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VEHICLE TYPE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the VEHICLE TYPE CODES which tell us about the type of vehicle that was involved in an accident. \n",
    "# Vehicle type 'k' refers to the kth vehicle that was involved in the accident. \n",
    "\n",
    "len(df[\"VEHICLE TYPE CODE 1\"].unique())\n",
    "\n",
    "# We have 1175 unique values within the dataset for VEHICLE TYPE CODE 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VEHICLE TYPE CODE 1\"].unique()[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"VEHICLE TYPE CODE 1\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will capitalize all entries in order to eliminate duplicates. \n",
    "\n",
    "df[[\"VEHICLE TYPE CODE 1\",\"VEHICLE TYPE CODE 2\",\"VEHICLE TYPE CODE 3\",\"VEHICLE TYPE CODE 4\",\"VEHICLE TYPE CODE 5\"]]=df[[\"VEHICLE TYPE CODE 1\",\"VEHICLE TYPE CODE 2\",\"VEHICLE TYPE CODE 3\",\"VEHICLE TYPE CODE 4\",\"VEHICLE TYPE CODE 5\"]].applymap(lambda x: str(x).upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put all the value counts for Vehicle Type code 1-5 in a dataframe. \n",
    "\n",
    "vehicletypedf=df[[\"VEHICLE TYPE CODE 1\",\"VEHICLE TYPE CODE 2\",\"VEHICLE TYPE CODE 3\",\"VEHICLE TYPE CODE 4\",\"VEHICLE TYPE CODE 5\"]].apply(pd.value_counts).sort_values(by=\"VEHICLE TYPE CODE 1\",ascending=False)\n",
    "vehicletypedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sum all the rows to reach a total.\n",
    "vehicletypedf[\"TOTAL\"]=vehicletypedf.sum(axis=1)\n",
    "vehicletypedf.head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we can see that Sedans and Station Wagons/Sport Utility Vehicles account for \n",
    "\n",
    "for n in vehicletypedf.index[:100]:\n",
    "    if n==\"NAN\":\n",
    "        pass\n",
    "    else:\n",
    "        print(n,\":\",(vehicletypedf[vehicletypedf.index==n][\"TOTAL\"].sum())/(vehicletypedf[vehicletypedf.index!=\"NAN\"][\"TOTAL\"].sum())*100,\"%\")\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
